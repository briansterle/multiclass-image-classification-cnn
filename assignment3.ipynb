{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "812fdf3a",
   "metadata": {},
   "source": [
    "# Assignment 3: Multi-Class Image Classification with CNNs\n",
    "\n",
    "*Author: Brian Sterle*\n",
    "\n",
    "*Date: April 15th, 2025*\n",
    "___\n",
    "### Installation\n",
    "Before running the notebook, setup the data:\n",
    "\n",
    "```bash\n",
    "# in root dir of project\n",
    "./fetch-data.sh\n",
    "```\n",
    "\n",
    "This fetches data from Kaggle via `curl` and unzips it to the `data/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fccb64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [code]\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "# Determine which device to use: cuda > mps > cpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() \n",
    "                      else \"mps\" if torch.backends.mps.is_available() \n",
    "                      else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Verify torch installation by creating a random tensor on the selected device\n",
    "x = torch.rand(5, 3, device=device)\n",
    "print(\"Random Tensor on selected device:\\n\", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a34baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3f9763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc96e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory paths for the dataset\n",
    "data_dir = 'data'\n",
    "train_dir = os.path.join(data_dir, 'seg_train', 'seg_train')\n",
    "test_dir = os.path.join(data_dir, 'seg_test', 'seg_test')\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define image size and transformation pipelines\n",
    "\n",
    "# choose an image size of 224x224\n",
    "image_size = 224\n",
    "\n",
    "# Transformation for the training set (includes data augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.RandomHorizontalFlip(),     # Random flip for augmentation\n",
    "    transforms.RandomRotation(15),           # Random rotation within ±15 degrees\n",
    "    transforms.ToTensor(),                   # Convert image to PyTorch tensor and scales [0,255] to [0,1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],   # Normalize based on ImageNet statistics\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Transformations for the validation and test sets (no augmentation, only resizing and normalization)\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets using ImageFolder.\n",
    "# Note: The ImageFolder directory structure should have subfolders for each class.\n",
    "train_dataset_full = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "\n",
    "# Print basic info about the dataset\n",
    "print(\"Classes:\", train_dataset_full.classes)\n",
    "print(\"Total images in the training folder:\", len(train_dataset_full))\n",
    "print(\"Total images in the test folder:\", len(test_dataset))\n",
    "\n",
    "# Create a stratified split (train/validation) for train_dataset_full.\n",
    "# Our overall dataset split should be: 70% train, 15% val, 15% test.\n",
    "# Since the test set is provided separately (15%), we split the training folder into:\n",
    "#    Train: 70/85 ≈ 82.35% of train_dataset_full\n",
    "#    Validation: 15/85 ≈ 17.65% of train_dataset_full\n",
    "\n",
    "def stratified_split(dataset, train_ratio=70/85):\n",
    "    \"\"\"\n",
    "    Splits the dataset into a train and validation set in a stratified manner.\n",
    "    \n",
    "    Parameters:\n",
    "        dataset: the full ImageFolder dataset.\n",
    "        train_ratio: proportion of samples (per class) to use for training.\n",
    "    \n",
    "    Returns:\n",
    "        train_indices: list of indices for the training set.\n",
    "        val_indices: list of indices for the validation set.\n",
    "    \"\"\"\n",
    "    targets = np.array(dataset.targets)\n",
    "    classes = np.unique(targets)\n",
    "    train_idx = []\n",
    "    val_idx = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        # Get indices for each class\n",
    "        cls_idx = np.where(targets == cls)[0]\n",
    "        n_samples = len(cls_idx)\n",
    "        n_train = int(np.floor(train_ratio * n_samples))\n",
    "        # Shuffle indices for randomness\n",
    "        np.random.shuffle(cls_idx)\n",
    "        # Assign indices for training and validation splits\n",
    "        train_idx.extend(cls_idx[:n_train])\n",
    "        val_idx.extend(cls_idx[n_train:])\n",
    "        \n",
    "    return train_idx, val_idx\n",
    "\n",
    "# Compute stratified indices using the ratio derived from a 70-15-15 split overall.\n",
    "train_idx, val_idx = stratified_split(train_dataset_full, train_ratio=70/85)\n",
    "print(f\"Total training samples after split: {len(train_idx)}\")\n",
    "print(f\"Total validation samples after split: {len(val_idx)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32e5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Subset datasets for training and validation\n",
    "train_dataset = Subset(train_dataset_full, train_idx)\n",
    "val_dataset = Subset(train_dataset_full, val_idx)\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"DataLoaders ready:\")\n",
    "print(\"  Training batches:\", len(train_loader))\n",
    "print(\"  Validation batches:\", len(val_loader))\n",
    "print(\"  Test batches:\", len(test_loader))\n",
    "\n",
    "# Create DataLoaders for each set\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "print(\"DataLoaders ready:\")\n",
    "print(\"  Training batches:\", len(train_loader))\n",
    "print(\"  Validation batches:\", len(val_loader))\n",
    "print(\"  Test batches:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple data exploration: Counting the number of samples per class in each subset.\n",
    "\n",
    "def count_labels(subset, dataset_full):\n",
    "    \"\"\"\n",
    "    Counts samples per class for a given subset.\n",
    "    \n",
    "    Parameters:\n",
    "        subset: a Subset object of the full dataset.\n",
    "        dataset_full: the full ImageFolder dataset (to retrieve class names and targets).\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary mapping class names to sample counts.\n",
    "    \"\"\"\n",
    "    counts = {class_name: 0 for class_name in dataset_full.classes}\n",
    "    for idx in subset.indices:\n",
    "        label = dataset_full.targets[idx]\n",
    "        class_name = dataset_full.classes[label]\n",
    "        counts[class_name] += 1\n",
    "    return counts\n",
    "\n",
    "train_counts = count_labels(train_dataset, train_dataset_full)\n",
    "val_counts = count_labels(val_dataset, train_dataset_full)\n",
    "\n",
    "# Count labels in test dataset manually (ImageFolder object has `imgs` attribute)\n",
    "test_counts = {class_name: 0 for class_name in test_dataset.classes}\n",
    "for _, label in test_dataset.imgs:\n",
    "    class_name = test_dataset.classes[label]\n",
    "    test_counts[class_name] += 1\n",
    "\n",
    "print(\"Training set samples per class:\")\n",
    "print(train_counts)\n",
    "print(\"\\nValidation set samples per class:\")\n",
    "print(val_counts)\n",
    "print(\"\\nTest set samples per class:\")\n",
    "print(test_counts)\n",
    "\n",
    "# Visualize a few sample images from the training set\n",
    "\n",
    "def imshow(img, title=None):\n",
    "    \"\"\"Display an image after unnormalizing it.\"\"\"\n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    # Unnormalize based on the ImageNet values\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    img = std * img + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Get one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Display 5 sample images from the batch\n",
    "# for i in range(5):\n",
    "#     label_name = train_dataset_full.classes[labels[i]]\n",
    "#     imshow(images[i], title=label_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e963877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20  # You can reduce this if necessary\n",
    "\n",
    "# Load pre-trained ResNet18 model and modify the final layer\n",
    "num_classes = len(train_dataset_full.classes)  # Ensure train_dataset_full is defined from Task 1\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all feature layers so only the final FC layer is trained\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)  # Replace final layer for our dataset\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Modified ResNet18 Model:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770a463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer (only parameters in model.fc will be updated)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "# If using CUDA, set up automatic mixed precision (AMP)\n",
    "use_amp = device.type == \"cuda\"\n",
    "\n",
    "# For mixed precision training (if available)\n",
    "scaler = torch.cuda.amp.GradScaler() if use_amp else None\n",
    "\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision if scaler is defined\n",
    "        if scaler:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Training loop using the modified training function with mixed precision (if applicable)\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "\n",
    "best_val_acc = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Time: {elapsed:.2f} sec\")\n",
    "    print(f\"  Training   -> Loss: {train_loss:.4f} | Accuracy: {train_acc*100:.2f}%\")\n",
    "    print(f\"  Validation -> Loss: {val_loss:.4f} | Accuracy: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict()\n",
    "        print(\"  * Best model updated!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m4pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
